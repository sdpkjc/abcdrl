[dqn]

[dqn.torch]

CartPole-v1 = """
    python abcdrl/dqn_torch.py \
        --trainer.env-id CartPole-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 500000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 10000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.05 \
        --trainer.exploration-fraction 0.5 \
        --trainer.batch-size 128 \
        --trainer.learning-rate 2.5e-4 \
        --trainer.learning-starts 10000 \
        --trainer.target-network-frequency 500 \
        --trainer.train-frequency 10 \
"""

BreakoutNoFrameskip-v4 = """
    python abcdrl/dqn_atari_torch.py \
        --trainer.env-id BreakoutNoFrameskip-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 10000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.01 \
        --trainer.exploration-fraction 0.1 \
        --trainer.batch-size 32 \
        --trainer.learning-rate 1e-4 \
        --trainer.learning-starts 50000 \
        --trainer.target-network-frequency 1000 \
        --trainer.train-frequency 4 \
"""

PongNoFrameskip-v4 = """
    python abcdrl/dqn_atari_torch.py \
        --trainer.env-id PongNoFrameskip-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 10000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.01 \
        --trainer.exploration-fraction 0.1 \
        --trainer.batch-size 32 \
        --trainer.learning-rate 1e-4 \
        --trainer.learning-starts 50000 \
        --trainer.target-network-frequency 1000 \
        --trainer.train-frequency 4 \
"""

BeamRiderNoFrameskip-v4 = """
    python abcdrl/dqn_atari_torch.py \
        --trainer.env-id BeamRiderNoFrameskip-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 10000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.01 \
        --trainer.exploration-fraction 0.1 \
        --trainer.batch-size 32 \
        --trainer.learning-rate 1e-4 \
        --trainer.learning-starts 50000 \
        --trainer.target-network-frequency 1000 \
        --trainer.train-frequency 4 \
"""

[dqn.tf]

CartPole-v1 = """
    python abcdrl/dqn_tf.py \
        --trainer.env-id CartPole-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 500000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 10000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.05 \
        --trainer.exploration-fraction 0.5 \
        --trainer.batch-size 128 \
        --trainer.learning-rate 2.5e-4 \
        --trainer.learning-starts 10000 \
        --trainer.target-network-frequency 500 \
        --trainer.train-frequency 10 \
"""

BreakoutNoFrameskip-v4 = """
    python abcdrl/dqn_atari_tf.py \
        --trainer.env-id BreakoutNoFrameskip-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 10000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.01 \
        --trainer.exploration-fraction 0.1 \
        --trainer.batch-size 32 \
        --trainer.learning-rate 1e-4 \
        --trainer.learning-starts 50000 \
        --trainer.target-network-frequency 1000 \
        --trainer.train-frequency 4 \
"""

PongNoFrameskip-v4 = """
    python abcdrl/dqn_atari_tf.py \
        --trainer.env-id PongNoFrameskip-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 10000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.01 \
        --trainer.exploration-fraction 0.1 \
        --trainer.batch-size 32 \
        --trainer.learning-rate 1e-4 \
        --trainer.learning-starts 50000 \
        --trainer.target-network-frequency 1000 \
        --trainer.train-frequency 4 \
"""

BeamRiderNoFrameskip-v4 = """
    python abcdrl/dqn_atari_tf.py \
        --trainer.env-id BeamRiderNoFrameskip-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 10000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.01 \
        --trainer.exploration-fraction 0.1 \
        --trainer.batch-size 32 \
        --trainer.learning-rate 1e-4 \
        --trainer.learning-starts 50000 \
        --trainer.target-network-frequency 1000 \
        --trainer.train-frequency 4 \
"""

[ddqn]


[ddqn.torch]

CartPole-v1 = """
    python abcdrl/ddqn_torch.py \
        --trainer.env-id CartPole-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 500000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 10000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.05 \
        --trainer.exploration-fraction 0.5 \
        --trainer.batch-size 128 \
        --trainer.learning-rate 2.5e-4 \
        --trainer.learning-starts 10000 \
        --trainer.target-network-frequency 500 \
        --trainer.train-frequency 10 \
"""

[ddqn.tf]

CartPole-v1 = """
    python abcdrl/ddqn_tf.py \
        --trainer.env-id CartPole-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 500000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 10000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.05 \
        --trainer.exploration-fraction 0.5 \
        --trainer.batch-size 128 \
        --trainer.learning-rate 2.5e-4 \
        --trainer.learning-starts 10000 \
        --trainer.target-network-frequency 500 \
        --trainer.train-frequency 10 \
"""

[pdqn]


[pdqn.torch]

CartPole-v1 = """
    python abcdrl/pdqn_torch.py \
        --trainer.env-id CartPole-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 500000 \
        --trainer.gamma 0.99 \
        --trainer.alpha 0.2 \
        --trainer.beta 0.6 \
        --trainer.buffer-size 10000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.05 \
        --trainer.exploration-fraction 0.5 \
        --trainer.batch-size 128 \
        --trainer.learning-rate 2.5e-4 \
        --trainer.learning-starts 10000 \
        --trainer.target-network-frequency 500 \
        --trainer.train-frequency 10 \
"""


[pdqn.tf]

CartPole-v1 = """
    python abcdrl/pdqn_tf.py \
        --trainer.env-id CartPole-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 500000 \
        --trainer.gamma 0.99 \
        --trainer.alpha 0.2 \
        --trainer.beta 0.6 \
        --trainer.buffer-size 10000 \
        --trainer.start-epsilon 1.0 \
        --trainer.end-epsilon 0.05 \
        --trainer.exploration-fraction 0.5 \
        --trainer.batch-size 128 \
        --trainer.learning-rate 2.5e-4 \
        --trainer.learning-starts 10000 \
        --trainer.target-network-frequency 500 \
        --trainer.train-frequency 10 \
"""


[ddpg]


[ddpg.torch]

Pendulum-v1 = """
    python abcdrl/ddpg_torch.py \
        --trainer.env-id Pendulum-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 50000 \
        --trainer.gamma 0.98 \
        --trainer.buffer-size 50000 \
        --trainer.exploration-noise 0.1 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 1e-3 \
        --trainer.tau 0.005 \
        --trainer.learning-starts 1000 \
        --trainer.train-frequency 4 \
        --trainer.policy-frequency 2 \
"""

Hopper-v4 = """
    python abcdrl/ddpg_torch.py \
        --trainer.env-id Hopper-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.exploration-noise 0.1 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 3e-4 \
        --trainer.tau 0.005 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
"""

Walker2d-v4 = """
    python abcdrl/ddpg_torch.py \
        --trainer.env-id Walker2d-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.exploration-noise 0.1 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 3e-4 \
        --trainer.tau 0.005 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
"""

HalfCheetah-v4 = """
    python abcdrl/ddpg_torch.py \
        --trainer.env-id HalfCheetah-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.exploration-noise 0.1 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 3e-4 \
        --trainer.tau 0.005 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
"""


[td3]


[td3.torch]

Pendulum-v1 = """
    python abcdrl/td3_torch.py \
        --trainer.env-id Pendulum-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 50000 \
        --trainer.gamma 0.98 \
        --trainer.buffer-size 50000 \
        --trainer.exploration-noise 0.1 \
        --trainer.noise-clip 0.5 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 1e-3 \
        --trainer.tau 0.005 \
        --trainer.policy-noise 0.2 \
        --trainer.learning-starts 1000 \
        --trainer.train-frequency 4 \
        --trainer.policy-frequency 2 \
"""

Hopper-v4 = """
    python abcdrl/td3_torch.py \
        --trainer.env-id Hopper-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.exploration-noise 0.1 \
        --trainer.noise-clip 0.5 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 3e-4 \
        --trainer.tau 0.005 \
        --trainer.policy-noise 0.2 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
"""

Walker2d-v4 = """
    python abcdrl/td3_torch.py \
        --trainer.env-id Walker2d-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.exploration-noise 0.1 \
        --trainer.noise-clip 0.5 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 3e-4 \
        --trainer.tau 0.005 \
        --trainer.policy-noise 0.2 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
"""

HalfCheetah-v4 = """
    python abcdrl/td3_torch.py \
        --trainer.env-id HalfCheetah-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.exploration-noise 0.1 \
        --trainer.noise-clip 0.5 \
        --trainer.batch-size 256 \
        --trainer.learning-rate 3e-4 \
        --trainer.tau 0.005 \
        --trainer.policy-noise 0.2 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
"""


[sac]

[sac.torch]

Pendulum-v1 = """
    python abcdrl/sac_torch.py \
        --trainer.env-id Pendulum-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 50000 \
        --trainer.gamma 0.98 \
        --trainer.buffer-size 50000 \
        --trainer.batch-size 256 \
        --trainer.q-lr 1e-3 \
        --trainer.policy-lr 3e-4 \
        --trainer.tau 0.005 \
        --trainer.alpha 0.2 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
        --trainer.target-network-frequency 1 \
"""

Hopper-v4 = """
    python abcdrl/sac_torch.py \
        --trainer.env-id Hopper-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.batch-size 256 \
        --trainer.q-lr 1e-3 \
        --trainer.policy-lr 3e-4 \
        --trainer.tau 0.005 \
        --trainer.alpha 0.2 \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
        --trainer.target-network-frequency 1 \
"""

Walker2d-v4 = """
    python abcdrl/sac_torch.py \
        --trainer.env-id Walker2d-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.batch-size 256 \
        --trainer.q-lr 1e-3 \
        --trainer.policy-lr 3e-4 \
        --trainer.tau 0.005 \
        --trainer.alpha 0.2 \
        --trainer.autotune True \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
        --trainer.target-network-frequency 1 \
"""

HalfCheetah-v4 = """
    python abcdrl/sac_torch.py \
        --trainer.env-id HalfCheetah-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.buffer-size 1000000 \
        --trainer.batch-size 256 \
        --trainer.q-lr 1e-3 \
        --trainer.policy-lr 3e-4 \
        --trainer.tau 0.005 \
        --trainer.alpha 0.2 \
        --trainer.autotune True \
        --trainer.learning-starts 25000 \
        --trainer.train-frequency 1 \
        --trainer.policy-frequency 2 \
        --trainer.target-network-frequency 1 \
"""


[ppo]

[ppo.torch]

Pendulum-v1 = """
    python abcdrl/ppo_torch.py \
        --trainer.env-id Pendulum-v1 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 50000 \
        --trainer.gamma 0.98 \
        --trainer.num-steps 128 \
        --trainer.learning-rate 1e-3 \
        --trainer.update-epochs 10 \
        --trainer.norm-adv True \
        --trainer.clip-coef 0.2 \
        --trainer.clip-vloss True \
        --trainer.ent-coef 0.0 \
        --trainer.vf-coef 0.5 \
        --trainer.max-grad-norm 0.5 \
        --trainer.num-minibatches 32 \
        --trainer.gae-lambda 0.95 \
"""

Hopper-v4 = """
    python abcdrl/ppo_torch.py \
        --trainer.env-id Hopper-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.num-steps 2048 \
        --trainer.learning-rate 3e-4 \
        --trainer.update-epochs 10 \
        --trainer.norm-adv True \
        --trainer.clip-coef 0.2 \
        --trainer.clip-vloss True \
        --trainer.ent-coef 0.0 \
        --trainer.vf-coef 0.5 \
        --trainer.max-grad-norm 0.5 \
        --trainer.num-minibatches 32 \
        --trainer.gae-lambda 0.95 \
"""

Walker2d-v4 = """
    python abcdrl/ppo_torch.py \
        --trainer.env-id Walker2d-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.num-steps 2048 \
        --trainer.learning-rate 3e-4 \
        --trainer.update-epochs 10 \
        --trainer.norm-adv True \
        --trainer.clip-coef 0.2 \
        --trainer.clip-vloss True \
        --trainer.ent-coef 0.0 \
        --trainer.vf-coef 0.5 \
        --trainer.max-grad-norm 0.5 \
        --trainer.num-minibatches 32 \
        --trainer.gae-lambda 0.95 \
"""

HalfCheetah-v4 = """
    python abcdrl/ppo_torch.py \
        --trainer.env-id HalfCheetah-v4 \
        --trainer.num-envs 1 \
        --trainer.total-timesteps 1000000 \
        --trainer.gamma 0.99 \
        --trainer.num-steps 2048 \
        --trainer.learning-rate 3e-4 \
        --trainer.update-epochs 10 \
        --trainer.norm-adv True \
        --trainer.clip-coef 0.2 \
        --trainer.clip-vloss True \
        --trainer.ent-coef 0.0 \
        --trainer.vf-coef 0.5 \
        --trainer.max-grad-norm 0.5 \
        --trainer.num-minibatches 32 \
        --trainer.gae-lambda 0.95 \
"""
